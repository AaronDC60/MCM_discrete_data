{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing of the Big Five personality test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the csv file containing the raw data\n",
    "data = pd.read_csv(\"../data/big5/data-final.csv\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing unwanted entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep samples if the number of samples from the IP address is equal to 1 (IPC = 1)\n",
    "data = data[data['IPC'] == 1]\n",
    "# Only keep columns with questions\n",
    "questions = data.keys()[:50]\n",
    "data = data[[i for i in questions]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for invalid samples\n",
    "invalid_entries = []\n",
    "\n",
    "for entry in data.index:\n",
    "    answers = data.loc[[entry]].values\n",
    "    # Remove samples with 0 as entry\n",
    "    if 0 in answers:\n",
    "        invalid_entries.append(entry)\n",
    "    # Remove samples that have the same answer for every question\n",
    "    elif len(np.unique(answers)) == 1:\n",
    "        invalid_entries.append(entry)\n",
    "    # Remove samples that contain nan values\n",
    "    elif np.isnan(answers).any():\n",
    "        invalid_entries.append(entry)\n",
    "\n",
    "data = data.drop(invalid_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_5states = data.to_numpy(dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep all five states (q=5)\n",
    "data_5states = data.to_numpy(dtype=int)\n",
    "\n",
    "# 11 componenents\n",
    "\n",
    "# N = 1000\n",
    "np.savetxt('../data/big5/Big5_q5_n11_N1000.dat', data_5states[:1000,[0,1,10,11,20,21,22,30,31,40,41]], fmt='%i', delimiter='')\n",
    "# N = 2000\n",
    "np.savetxt('../data/big5/Big5_q5_n11_N2000.dat', data_5states[:2000,[0,1,10,11,20,21,22,30,31,40,41]], fmt='%i', delimiter='')\n",
    "# N = 10_000\n",
    "np.savetxt('../data/big5/Big5_q5_n11_N10000.dat', data_5states[:10_000,[0,1,10,11,20,21,22,30,31,40,41]], fmt='%i', delimiter='')\n",
    "# N = 100_000\n",
    "np.savetxt('../data/big5/Big5_q5_n11_N100000.dat', data_5states[:100_000,[0,1,10,11,20,21,22,30,31,40,41]], fmt='%i', delimiter='')\n",
    "# N = 200_000\n",
    "np.savetxt('../data/big5/Big5_q5_n11_N200000.dat', data_5states[:200_000,[0,1,10,11,20,21,22,30,31,40,41]], fmt='%i', delimiter='')\n",
    "# Complete dataset\n",
    "np.savetxt('../data/big5/Big5_q5_n11.dat', data_5states[:,[0,1,10,11,20,21,22,30,31,40,41]], fmt='%i', delimiter='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12 components\n",
    "\n",
    "# N = 10_000\n",
    "np.savetxt('../data/big5/Big5_q5_n12_N10000.dat', data_5states[:10_000,[0,1,2,10,11,20,21,22,30,31,40,41]], fmt='%i', delimiter='')\n",
    "# N = 100_000\n",
    "np.savetxt('../data/big5/Big5_q5_n12_N100000.dat', data_5states[:100_000,[0,1,2,10,11,20,21,22,30,31,40,41]], fmt='%i', delimiter='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13 components\n",
    "\n",
    "# N = 10_000\n",
    "np.savetxt('../data/big5/Big5_q5_n13_N10000.dat', data_5states[:10_000,[0,1,2,10,11,12,20,21,22,30,31,40,41]], fmt='%i', delimiter='')\n",
    "# N = 100_000\n",
    "np.savetxt('../data/big5/Big5_q5_n13_N100000.dat', data_5states[:100_000,[0,1,2,10,11,12,20,21,22,30,31,40,41]], fmt='%i', delimiter='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14 components\n",
    "\n",
    "# N = 10_000\n",
    "np.savetxt('../data/big5/Big5_q5_n14_N10000.dat', data_5states[:10_000,[0,1,2,10,11,12,20,21,22,30,31,32,40,41]], fmt='%i', delimiter='')\n",
    "# N = 100_000\n",
    "np.savetxt('../data/big5/Big5_q5_n14_N100000.dat', data_5states[:100_000,[0,1,2,10,11,12,20,21,22,30,31,32,40,41]], fmt='%i', delimiter='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15 components\n",
    "\n",
    "# N = 10_000\n",
    "np.savetxt('../data/big5/Big5_q5_n15_N10000.dat', data_5states[:10_000,[0,1,2,10,11,12,20,21,22,30,31,32,40,41,42]], fmt='%i', delimiter='')\n",
    "# N = 100_000\n",
    "np.savetxt('../data/big5/Big5_q5_n15_N100000.dat', data_5states[:100_000,[0,1,2,10,11,12,20,21,22,30,31,32,40,41,42]], fmt='%i', delimiter='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discretizing data to have 3 different states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_3states = data.to_numpy(dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scheme 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Map score of 4 (slightly agree) and 5 (agree) to state $\\alpha = 2$\n",
    "- Map score of 3 (neutral) to state $\\alpha = 1$\n",
    "- Map score of 2 (slightly disagree) and 1 (disagree) to state $\\alpha = 0$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_3states_v1 = np.copy(data_3states)\n",
    "\n",
    "data_3states_v1[data_3states_v1 < 3 ] = 0\n",
    "data_3states_v1[data_3states_v1 == 3] = 1\n",
    "data_3states_v1[data_3states_v1 > 3] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as strings\n",
    "np.savetxt('../data/Big5/Big5_q3_v1.dat', data_3states_v1, fmt='%i', delimiter='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduced data (columns: 0,1;10,11;20,21,22;30,31;40,41)\n",
    "# Only first 1000 samples\n",
    "small_data_set = data_3states_v1[:1000,[0,1,10,11,20,21,22,30,31,40,41]]\n",
    "np.savetxt('../data/Big5/Big5_q3_v1_n11_N1000.dat', small_data_set, fmt='%i', delimiter='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scheme 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate the average across, $\\bar{x}$, the samples for every question.\n",
    "- Choose value for $\\epsilon$\n",
    "\n",
    "* Map value above $\\bar{x} + \\epsilon$ to state $\\alpha = 2$\n",
    "* Map value between $\\bar{x} + \\epsilon$ and $\\bar{x} - \\epsilon$ to state $\\alpha = 1$\n",
    "* Map value below $\\bar{x} - \\epsilon$ to state $\\alpha = 0$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_3states_v2 = np.copy(data_3states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average across samples for every question\n",
    "avg = np.average(data_3states_v2, axis=0)\n",
    "# Value for epsilon\n",
    "eps = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_3states_v2[data_3states < (avg - eps)] = 0\n",
    "data_3states_v2[data_3states > (avg + eps)] = 2\n",
    "data_3states_v2[np.all((data_3states > (avg - eps), data_3states < (avg + eps)), axis=0)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as strings\n",
    "np.savetxt('../data/Big5/Big5_q3_v2.dat', data_3states_v1, fmt='%i', delimiter='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduced data (columns: 0,1;10,11;20,21,22;30,31;40,41)\n",
    "# Only first 1000 samples\n",
    "small_data_set = data_3states_v2[:1000,[0,1,10,11,20,21,22,30,31,40,41]]\n",
    "np.savetxt('../data/Big5/Big5_q3_v2_n11_N1000.dat', small_data_set, fmt='%i', delimiter='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcm_discrete",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
